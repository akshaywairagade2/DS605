Training with a single process on 1 GPUs.
home/sanat/.cache/torch/hub/checkpoints 511 999999999
/home/sanat/.cache/torch/hub/checkpoints creating dir
Data processing configuration for current model + dataset:
	input_size: (3, 224, 224)
	interpolation: bicubic
	mean: (0.5, 0.5, 0.5)
	std: (0.5, 0.5, 0.5)
	crop_pct: 0.9
ssf_scale_1
ssf_shift_1
patch_embed.ssf_scale_1
patch_embed.ssf_shift_1
blocks.0.ssf_scale_1
blocks.0.ssf_shift_1
blocks.0.ssf_scale_2
blocks.0.ssf_shift_2
blocks.0.attn.ssf_scale_1
blocks.0.attn.ssf_shift_1
blocks.0.attn.ssf_scale_2
blocks.0.attn.ssf_shift_2
blocks.0.mlp.ssf_scale_1
blocks.0.mlp.ssf_shift_1
blocks.0.mlp.ssf_scale_2
blocks.0.mlp.ssf_shift_2
blocks.1.ssf_scale_1
blocks.1.ssf_shift_1
blocks.1.ssf_scale_2
blocks.1.ssf_shift_2
blocks.1.attn.ssf_scale_1
blocks.1.attn.ssf_shift_1
blocks.1.attn.ssf_scale_2
blocks.1.attn.ssf_shift_2
blocks.1.mlp.ssf_scale_1
blocks.1.mlp.ssf_shift_1
blocks.1.mlp.ssf_scale_2
blocks.1.mlp.ssf_shift_2
blocks.2.ssf_scale_1
blocks.2.ssf_shift_1
blocks.2.ssf_scale_2
blocks.2.ssf_shift_2
blocks.2.attn.ssf_scale_1
blocks.2.attn.ssf_shift_1
blocks.2.attn.ssf_scale_2
blocks.2.attn.ssf_shift_2
blocks.2.mlp.ssf_scale_1
blocks.2.mlp.ssf_shift_1
blocks.2.mlp.ssf_scale_2
blocks.2.mlp.ssf_shift_2
blocks.3.ssf_scale_1
blocks.3.ssf_shift_1
blocks.3.ssf_scale_2
blocks.3.ssf_shift_2
blocks.3.attn.ssf_scale_1
blocks.3.attn.ssf_shift_1
blocks.3.attn.ssf_scale_2
blocks.3.attn.ssf_shift_2
blocks.3.mlp.ssf_scale_1
blocks.3.mlp.ssf_shift_1
blocks.3.mlp.ssf_scale_2
blocks.3.mlp.ssf_shift_2
blocks.4.ssf_scale_1
blocks.4.ssf_shift_1
blocks.4.ssf_scale_2
blocks.4.ssf_shift_2
blocks.4.attn.ssf_scale_1
blocks.4.attn.ssf_shift_1
blocks.4.attn.ssf_scale_2
blocks.4.attn.ssf_shift_2
blocks.4.mlp.ssf_scale_1
blocks.4.mlp.ssf_shift_1
blocks.4.mlp.ssf_scale_2
blocks.4.mlp.ssf_shift_2
blocks.5.ssf_scale_1
blocks.5.ssf_shift_1
blocks.5.ssf_scale_2
blocks.5.ssf_shift_2
blocks.5.attn.ssf_scale_1
blocks.5.attn.ssf_shift_1
blocks.5.attn.ssf_scale_2
blocks.5.attn.ssf_shift_2
blocks.5.mlp.ssf_scale_1
blocks.5.mlp.ssf_shift_1
blocks.5.mlp.ssf_scale_2
blocks.5.mlp.ssf_shift_2
blocks.6.ssf_scale_1
blocks.6.ssf_shift_1
blocks.6.ssf_scale_2
blocks.6.ssf_shift_2
blocks.6.attn.ssf_scale_1
blocks.6.attn.ssf_shift_1
blocks.6.attn.ssf_scale_2
blocks.6.attn.ssf_shift_2
blocks.6.mlp.ssf_scale_1
blocks.6.mlp.ssf_shift_1
blocks.6.mlp.ssf_scale_2
blocks.6.mlp.ssf_shift_2
blocks.7.ssf_scale_1
blocks.7.ssf_shift_1
blocks.7.ssf_scale_2
blocks.7.ssf_shift_2
blocks.7.attn.ssf_scale_1
blocks.7.attn.ssf_shift_1
blocks.7.attn.ssf_scale_2
blocks.7.attn.ssf_shift_2
blocks.7.mlp.ssf_scale_1
blocks.7.mlp.ssf_shift_1
blocks.7.mlp.ssf_scale_2
blocks.7.mlp.ssf_shift_2
blocks.8.ssf_scale_1
blocks.8.ssf_shift_1
blocks.8.ssf_scale_2
blocks.8.ssf_shift_2
blocks.8.attn.ssf_scale_1
blocks.8.attn.ssf_shift_1
blocks.8.attn.ssf_scale_2
blocks.8.attn.ssf_shift_2
blocks.8.mlp.ssf_scale_1
blocks.8.mlp.ssf_shift_1
blocks.8.mlp.ssf_scale_2
blocks.8.mlp.ssf_shift_2
blocks.9.ssf_scale_1
blocks.9.ssf_shift_1
blocks.9.ssf_scale_2
blocks.9.ssf_shift_2
blocks.9.attn.ssf_scale_1
blocks.9.attn.ssf_shift_1
blocks.9.attn.ssf_scale_2
blocks.9.attn.ssf_shift_2
blocks.9.mlp.ssf_scale_1
blocks.9.mlp.ssf_shift_1
blocks.9.mlp.ssf_scale_2
blocks.9.mlp.ssf_shift_2
blocks.10.ssf_scale_1
blocks.10.ssf_shift_1
blocks.10.ssf_scale_2
blocks.10.ssf_shift_2
blocks.10.attn.ssf_scale_1
blocks.10.attn.ssf_shift_1
blocks.10.attn.ssf_scale_2
blocks.10.attn.ssf_shift_2
blocks.10.mlp.ssf_scale_1
blocks.10.mlp.ssf_shift_1
blocks.10.mlp.ssf_scale_2
blocks.10.mlp.ssf_shift_2
blocks.11.ssf_scale_1
blocks.11.ssf_shift_1
blocks.11.ssf_scale_2
blocks.11.ssf_shift_2
blocks.11.attn.ssf_scale_1
blocks.11.attn.ssf_shift_1
blocks.11.attn.ssf_scale_2
blocks.11.attn.ssf_shift_2
blocks.11.mlp.ssf_scale_1
blocks.11.mlp.ssf_shift_1
blocks.11.mlp.ssf_scale_2
blocks.11.mlp.ssf_shift_2
head.weight
head.bias
freezing parameters finished!
Model vit_base_patch16_224_in21k created, param count:86081380
number of params for requires grad: 282724
Using native Torch AMP. Training in mixed precision.
Scheduled epochs: 110
True
/path/to/cifar100 root integrity
train 16019d7e3df5f24257cddd939b257f8d
/path/to/cifar100/cifar-100-python/train fpath integrity
/path/to/cifar100/cifar-100-python/train file_path
/home/sanat/Documents/Notes/Semester 7/DS605/DS605-20231119T065028Z-001/DS605/SSF
True
_load_meta /path/to/cifar100/cifar-100-python/meta
False
/path/to/cifar100 root integrity
train 16019d7e3df5f24257cddd939b257f8d
/path/to/cifar100/cifar-100-python/train fpath integrity
/path/to/cifar100/cifar-100-python/test file_path
/home/sanat/Documents/Notes/Semester 7/DS605/DS605-20231119T065028Z-001/DS605/SSF
True
_load_meta /path/to/cifar100/cifar-100-python/meta
utput/vit_base_patch16_224_in21k/cifar_100/ssf/20231120-125001-vit_base_patch16_224_in21k-224 511 999999999
output/vit_base_patch16_224_in21k/cifar_100/ssf/20231120-125001-vit_base_patch16_224_in21k-224 creating dir
output/vit_base_patch16_224_in21k/cifar_100/ssf/20231120-125001-vit_base_patch16_224_in21k-224 output_dir
Train: 0 [   0/4166 (  0%)]  Loss: 5.777 (5.78)  Time: 2.826s,    4.25/s  (2.826s,    4.25/s)  LR: 1.000e-07  Data: 0.232 (0.232)
Train: 0 [  50/4166 (  1%)]  Loss: 5.557 (5.86)  Time: 2.368s,    5.07/s  (2.372s,    5.06/s)  LR: 1.000e-07  Data: 0.002 (0.006)
Train: 0 [ 100/4166 (  2%)]  Loss: 5.715 (5.84)  Time: 2.423s,    4.95/s  (2.388s,    5.02/s)  LR: 1.000e-07  Data: 0.002 (0.004)
Train: 0 [ 150/4166 (  4%)]  Loss: 7.125 (5.85)  Time: 2.465s,    4.87/s  (2.413s,    4.97/s)  LR: 1.000e-07  Data: 0.002 (0.003)
Train: 0 [ 200/4166 (  5%)]  Loss: 4.903 (5.83)  Time: 2.453s,    4.89/s  (2.420s,    4.96/s)  LR: 1.000e-07  Data: 0.002 (0.003)
Train: 0 [ 250/4166 (  6%)]  Loss: 5.392 (5.84)  Time: 2.459s,    4.88/s  (2.428s,    4.94/s)  LR: 1.000e-07  Data: 0.002 (0.003)
Train: 0 [ 300/4166 (  7%)]  Loss: 5.506 (5.85)  Time: 2.458s,    4.88/s  (2.433s,    4.93/s)  LR: 1.000e-07  Data: 0.002 (0.003)
Train: 0 [ 350/4166 (  8%)]  Loss: 5.906 (5.83)  Time: 2.509s,    4.78/s  (2.440s,    4.92/s)  LR: 1.000e-07  Data: 0.002 (0.003)
Train: 0 [ 400/4166 ( 10%)]  Loss: 6.057 (5.84)  Time: 2.560s,    4.69/s  (2.448s,    4.90/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 450/4166 ( 11%)]  Loss: 6.525 (5.84)  Time: 2.494s,    4.81/s  (2.453s,    4.89/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 500/4166 ( 12%)]  Loss: 6.269 (5.83)  Time: 2.524s,    4.75/s  (2.458s,    4.88/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 550/4166 ( 13%)]  Loss: 6.051 (5.83)  Time: 2.465s,    4.87/s  (2.463s,    4.87/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 600/4166 ( 14%)]  Loss: 5.585 (5.83)  Time: 2.489s,    4.82/s  (2.465s,    4.87/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 650/4166 ( 16%)]  Loss: 5.923 (5.83)  Time: 2.484s,    4.83/s  (2.467s,    4.86/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 700/4166 ( 17%)]  Loss: 5.384 (5.82)  Time: 2.486s,    4.83/s  (2.468s,    4.86/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 750/4166 ( 18%)]  Loss: 6.072 (5.82)  Time: 2.491s,    4.82/s  (2.470s,    4.86/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 800/4166 ( 19%)]  Loss: 6.015 (5.82)  Time: 2.548s,    4.71/s  (2.473s,    4.85/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 850/4166 ( 20%)]  Loss: 5.631 (5.81)  Time: 2.526s,    4.75/s  (2.476s,    4.85/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 900/4166 ( 22%)]  Loss: 6.659 (5.82)  Time: 2.527s,    4.75/s  (2.479s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [ 950/4166 ( 23%)]  Loss: 5.938 (5.81)  Time: 2.487s,    4.82/s  (2.479s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1000/4166 ( 24%)]  Loss: 5.802 (5.81)  Time: 2.456s,    4.89/s  (2.478s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1050/4166 ( 25%)]  Loss: 5.129 (5.81)  Time: 2.466s,    4.87/s  (2.478s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1100/4166 ( 26%)]  Loss: 5.516 (5.81)  Time: 2.474s,    4.85/s  (2.478s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
+Train: 0 [1150/4166 ( 28%)]  Loss: 5.033 (5.81)  Time: 2.507s,    4.79/s  (2.478s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1200/4166 ( 29%)]  Loss: 5.656 (5.81)  Time: 2.468s,    4.86/s  (2.478s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1250/4166 ( 30%)]  Loss: 6.252 (5.81)  Time: 2.480s,    4.84/s  (2.478s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1300/4166 ( 31%)]  Loss: 5.470 (5.81)  Time: 2.494s,    4.81/s  (2.479s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1350/4166 ( 32%)]  Loss: 5.263 (5.81)  Time: 2.486s,    4.83/s  (2.479s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1400/4166 ( 34%)]  Loss: 5.584 (5.81)  Time: 2.472s,    4.85/s  (2.479s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1450/4166 ( 35%)]  Loss: 5.781 (5.81)  Time: 2.488s,    4.82/s  (2.479s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1500/4166 ( 36%)]  Loss: 5.208 (5.81)  Time: 2.490s,    4.82/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1550/4166 ( 37%)]  Loss: 4.369 (5.80)  Time: 2.482s,    4.83/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1600/4166 ( 38%)]  Loss: 5.152 (5.80)  Time: 2.512s,    4.78/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1650/4166 ( 40%)]  Loss: 5.867 (5.80)  Time: 2.506s,    4.79/s  (2.482s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1700/4166 ( 41%)]  Loss: 6.315 (5.80)  Time: 2.513s,    4.77/s  (2.482s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1750/4166 ( 42%)]  Loss: 5.438 (5.80)  Time: 2.449s,    4.90/s  (2.482s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1800/4166 ( 43%)]  Loss: 6.439 (5.80)  Time: 2.476s,    4.85/s  (2.482s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1850/4166 ( 44%)]  Loss: 5.646 (5.80)  Time: 2.468s,    4.86/s  (2.482s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1900/4166 ( 46%)]  Loss: 6.464 (5.80)  Time: 2.469s,    4.86/s  (2.482s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [1950/4166 ( 47%)]  Loss: 6.144 (5.80)  Time: 2.489s,    4.82/s  (2.482s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2000/4166 ( 48%)]  Loss: 6.097 (5.80)  Time: 2.449s,    4.90/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2050/4166 ( 49%)]  Loss: 5.304 (5.80)  Time: 2.447s,    4.90/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2100/4166 ( 50%)]  Loss: 6.680 (5.79)  Time: 2.451s,    4.90/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2150/4166 ( 52%)]  Loss: 5.762 (5.79)  Time: 2.520s,    4.76/s  (2.479s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2200/4166 ( 53%)]  Loss: 5.820 (5.79)  Time: 2.502s,    4.80/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2250/4166 ( 54%)]  Loss: 5.118 (5.79)  Time: 2.514s,    4.77/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2300/4166 ( 55%)]  Loss: 5.561 (5.79)  Time: 2.506s,    4.79/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2350/4166 ( 56%)]  Loss: 5.807 (5.79)  Time: 2.513s,    4.77/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2400/4166 ( 58%)]  Loss: 5.563 (5.79)  Time: 2.502s,    4.80/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2450/4166 ( 59%)]  Loss: 5.394 (5.79)  Time: 2.521s,    4.76/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2500/4166 ( 60%)]  Loss: 5.556 (5.79)  Time: 2.486s,    4.83/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2550/4166 ( 61%)]  Loss: 5.707 (5.78)  Time: 2.510s,    4.78/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2600/4166 ( 62%)]  Loss: 6.080 (5.78)  Time: 2.496s,    4.81/s  (2.482s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2650/4166 ( 64%)]  Loss: 5.608 (5.78)  Time: 2.469s,    4.86/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2700/4166 ( 65%)]  Loss: 6.116 (5.78)  Time: 2.472s,    4.85/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2750/4166 ( 66%)]  Loss: 5.892 (5.78)  Time: 2.467s,    4.86/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2800/4166 ( 67%)]  Loss: 5.760 (5.78)  Time: 2.466s,    4.87/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2850/4166 ( 68%)]  Loss: 5.635 (5.78)  Time: 2.466s,    4.87/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2900/4166 ( 70%)]  Loss: 5.821 (5.78)  Time: 2.474s,    4.85/s  (2.480s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [2950/4166 ( 71%)]  Loss: 5.356 (5.78)  Time: 2.542s,    4.72/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3000/4166 ( 72%)]  Loss: 5.998 (5.78)  Time: 2.506s,    4.79/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3050/4166 ( 73%)]  Loss: 5.925 (5.78)  Time: 2.517s,    4.77/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3100/4166 ( 74%)]  Loss: 5.774 (5.78)  Time: 2.493s,    4.81/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3150/4166 ( 76%)]  Loss: 5.490 (5.78)  Time: 2.515s,    4.77/s  (2.481s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3200/4166 ( 77%)]  Loss: 5.322 (5.78)  Time: 2.507s,    4.79/s  (2.482s,    4.84/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3250/4166 ( 78%)]  Loss: 5.858 (5.77)  Time: 2.519s,    4.76/s  (2.482s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3300/4166 ( 79%)]  Loss: 5.502 (5.77)  Time: 2.506s,    4.79/s  (2.482s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3350/4166 ( 80%)]  Loss: 6.139 (5.77)  Time: 2.504s,    4.79/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3400/4166 ( 82%)]  Loss: 5.082 (5.77)  Time: 2.485s,    4.83/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3450/4166 ( 83%)]  Loss: 5.348 (5.77)  Time: 2.487s,    4.82/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3500/4166 ( 84%)]  Loss: 5.940 (5.77)  Time: 2.487s,    4.82/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3550/4166 ( 85%)]  Loss: 5.166 (5.77)  Time: 2.495s,    4.81/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3600/4166 ( 86%)]  Loss: 5.278 (5.77)  Time: 2.456s,    4.89/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3650/4166 ( 88%)]  Loss: 5.585 (5.77)  Time: 2.479s,    4.84/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3700/4166 ( 89%)]  Loss: 5.632 (5.77)  Time: 2.445s,    4.91/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3750/4166 ( 90%)]  Loss: 5.721 (5.77)  Time: 2.537s,    4.73/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3800/4166 ( 91%)]  Loss: 5.857 (5.77)  Time: 2.491s,    4.82/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3850/4166 ( 92%)]  Loss: 5.304 (5.76)  Time: 2.488s,    4.82/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3900/4166 ( 94%)]  Loss: 5.956 (5.76)  Time: 2.478s,    4.84/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [3950/4166 ( 95%)]  Loss: 6.204 (5.76)  Time: 2.499s,    4.80/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [4000/4166 ( 96%)]  Loss: 5.730 (5.76)  Time: 2.495s,    4.81/s  (2.484s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [4050/4166 ( 97%)]  Loss: 6.200 (5.76)  Time: 2.466s,    4.87/s  (2.484s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [4100/4166 ( 98%)]  Loss: 5.620 (5.76)  Time: 2.464s,    4.87/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [4150/4166 (100%)]  Loss: 4.758 (5.76)  Time: 2.514s,    4.77/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.002 (0.002)
Train: 0 [4165/4166 (100%)]  Loss: 4.950 (5.76)  Time: 2.503s,    4.79/s  (2.483s,    4.83/s)  LR: 1.000e-07  Data: 0.000 (0.002)
Test: [   0/4166]  Time: 1.389 (1.389)  Loss:  5.5508 (5.5508)  Acc@1:  8.3333 ( 8.3333)  Acc@5:  8.3333 ( 8.3333)
Test: [  50/4166]  Time: 1.215 (1.196)  Loss:  7.0312 (5.9869)  Acc@1:  0.0000 ( 1.3072)  Acc@5:  0.0000 ( 6.2092)
Test: [ 100/4166]  Time: 1.197 (1.198)  Loss:  6.3789 (5.9919)  Acc@1:  0.0000 ( 1.6502)  Acc@5:  0.0000 ( 6.4356)
Test: [ 150/4166]  Time: 1.175 (1.197)  Loss:  5.9883 (6.0050)  Acc@1:  0.0000 ( 1.6556)  Acc@5:  0.0000 ( 6.2914)
Test: [ 200/4166]  Time: 1.196 (1.198)  Loss:  5.7344 (5.9850)  Acc@1:  0.0000 ( 1.6169)  Acc@5: 16.6667 ( 6.3433)
Test: [ 250/4166]  Time: 1.217 (1.199)  Loss:  6.0703 (5.9788)  Acc@1:  0.0000 ( 1.6268)  Acc@5:  8.3333 ( 6.6401)
Test: [ 300/4166]  Time: 1.212 (1.200)  Loss:  5.2812 (5.9897)  Acc@1:  8.3333 ( 1.6058)  Acc@5: 25.0000 ( 6.8660)
Test: [ 350/4166]  Time: 1.196 (1.201)  Loss:  6.0039 (6.0158)  Acc@1:  0.0000 ( 1.4245)  Acc@5:  0.0000 ( 6.5527)
Test: [ 400/4166]  Time: 1.198 (1.202)  Loss:  6.3125 (6.0164)  Acc@1:  0.0000 ( 1.3924)  Acc@5:  0.0000 ( 6.4007)
Test: [ 450/4166]  Time: 1.221 (1.201)  Loss:  6.2695 (6.0130)  Acc@1:  0.0000 ( 1.3673)  Acc@5:  0.0000 ( 6.2454)
Test: [ 500/4166]  Time: 1.197 (1.201)  Loss:  6.2539 (6.0070)  Acc@1:  0.0000 ( 1.3806)  Acc@5:  0.0000 ( 6.2708)
Test: [ 550/4166]  Time: 1.195 (1.201)  Loss:  6.2422 (6.0096)  Acc@1:  0.0000 ( 1.3309)  Acc@5:  0.0000 ( 6.1857)
Test: [ 600/4166]  Time: 1.196 (1.201)  Loss:  5.8047 (6.0126)  Acc@1:  0.0000 ( 1.3311)  Acc@5:  0.0000 ( 6.0871)
Test: [ 650/4166]  Time: 1.214 (1.201)  Loss:  6.3008 (6.0103)  Acc@1:  0.0000 ( 1.3953)  Acc@5:  8.3333 ( 6.0932)
Test: [ 700/4166]  Time: 1.201 (1.200)  Loss:  5.9141 (6.0134)  Acc@1:  0.0000 ( 1.3671)  Acc@5:  8.3333 ( 6.1222)
Test: [ 750/4166]  Time: 1.167 (1.200)  Loss:  5.7344 (6.0191)  Acc@1:  0.0000 ( 1.3427)  Acc@5:  0.0000 ( 6.0697)
Test: [ 800/4166]  Time: 1.183 (1.198)  Loss:  6.1562 (6.0194)  Acc@1:  8.3333 ( 1.3317)  Acc@5:  8.3333 ( 6.0341)
Test: [ 850/4166]  Time: 1.175 (1.197)  Loss:  5.6797 (6.0115)  Acc@1:  0.0000 ( 1.3611)  Acc@5:  0.0000 ( 6.0909)
Test: [ 900/4166]  Time: 1.190 (1.197)  Loss:  6.0234 (6.0127)  Acc@1:  0.0000 ( 1.3504)  Acc@5:  8.3333 ( 6.1506)
Test: [ 950/4166]  Time: 1.199 (1.197)  Loss:  6.2461 (6.0153)  Acc@1:  0.0000 ( 1.3670)  Acc@5:  0.0000 ( 6.1514)
Test: [1000/4166]  Time: 1.194 (1.196)  Loss:  6.0938 (6.0194)  Acc@1:  0.0000 ( 1.3487)  Acc@5:  8.3333 ( 6.1439)
Test: [1050/4166]  Time: 1.199 (1.196)  Loss:  6.4453 (6.0209)  Acc@1:  0.0000 ( 1.3479)  Acc@5:  0.0000 ( 6.0974)
Test: [1100/4166]  Time: 1.192 (1.196)  Loss:  6.0781 (6.0255)  Acc@1:  0.0000 ( 1.3246)  Acc@5:  0.0000 ( 6.0551)
Test: [1150/4166]  Time: 1.227 (1.196)  Loss:  5.7109 (6.0276)  Acc@1:  8.3333 ( 1.3611)  Acc@5:  8.3333 ( 6.0310)
Test: [1200/4166]  Time: 1.190 (1.196)  Loss:  5.5703 (6.0269)  Acc@1:  0.0000 ( 1.3600)  Acc@5:  8.3333 ( 6.0089)
Test: [1250/4166]  Time: 1.193 (1.196)  Loss:  6.9609 (6.0294)  Acc@1:  0.0000 ( 1.3456)  Acc@5:  0.0000 ( 6.0218)
Test: [1300/4166]  Time: 1.192 (1.196)  Loss:  7.3008 (6.0295)  Acc@1:  0.0000 ( 1.3323)  Acc@5:  0.0000 ( 6.0530)
Test: [1350/4166]  Time: 1.192 (1.196)  Loss:  6.3047 (6.0316)  Acc@1:  0.0000 ( 1.3447)  Acc@5: 25.0000 ( 6.0572)
Test: [1400/4166]  Time: 1.193 (1.196)  Loss:  5.8516 (6.0337)  Acc@1:  0.0000 ( 1.3443)  Acc@5:  8.3333 ( 6.0255)
Test: [1450/4166]  Time: 1.195 (1.196)  Loss:  7.0234 (6.0378)  Acc@1:  0.0000 ( 1.3382)  Acc@5:  0.0000 ( 6.0188)
Test: [1500/4166]  Time: 1.217 (1.197)  Loss:  5.2539 (6.0373)  Acc@1:  0.0000 ( 1.3491)  Acc@5:  8.3333 ( 6.0127)
Test: [1550/4166]  Time: 1.189 (1.198)  Loss:  6.6719 (6.0389)  Acc@1:  0.0000 ( 1.3486)  Acc@5:  0.0000 ( 6.0391)
Test: [1600/4166]  Time: 1.189 (1.197)  Loss:  5.8633 (6.0376)  Acc@1:  0.0000 ( 1.3429)  Acc@5:  0.0000 ( 6.0691)
Test: [1650/4166]  Time: 1.202 (1.197)  Loss:  6.5977 (6.0390)  Acc@1:  0.0000 ( 1.3376)  Acc@5:  0.0000 ( 6.0771)
Test: [1700/4166]  Time: 1.213 (1.198)  Loss:  5.6445 (6.0405)  Acc@1:  0.0000 ( 1.3325)  Acc@5:  8.3333 ( 6.0847)
Test: [1750/4166]  Time: 1.195 (1.198)  Loss:  5.6133 (6.0415)  Acc@1:  8.3333 ( 1.3468)  Acc@5: 16.6667 ( 6.1298)
Test: [1800/4166]  Time: 1.214 (1.198)  Loss:  6.1289 (6.0421)  Acc@1:  0.0000 ( 1.3372)  Acc@5:  8.3333 ( 6.1262)
Test: [1850/4166]  Time: 1.221 (1.199)  Loss:  5.9297 (6.0404)  Acc@1:  0.0000 ( 1.3506)  Acc@5: 16.6667 ( 6.1318)
Test: [1900/4166]  Time: 1.214 (1.200)  Loss:  5.6016 (6.0382)  Acc@1:  0.0000 ( 1.3502)  Acc@5: 16.6667 ( 6.1152)
Test: [1950/4166]  Time: 1.234 (1.201)  Loss:  6.0703 (6.0337)  Acc@1:  0.0000 ( 1.3497)  Acc@5:  0.0000 ( 6.1421)
Test: [2000/4166]  Time: 1.254 (1.202)  Loss:  5.5156 (6.0326)  Acc@1:  8.3333 ( 1.3452)  Acc@5:  8.3333 ( 6.1428)
Test: [2050/4166]  Time: 1.246 (1.202)  Loss:  5.3945 (6.0324)  Acc@1:  0.0000 ( 1.3693)  Acc@5:  0.0000 ( 6.1840)
Test: [2100/4166]  Time: 1.223 (1.203)  Loss:  6.3203 (6.0319)  Acc@1:  0.0000 ( 1.3605)  Acc@5:  0.0000 ( 6.1875)
Test: [2150/4166]  Time: 1.221 (1.204)  Loss:  5.9414 (6.0302)  Acc@1:  0.0000 ( 1.3521)  Acc@5:  0.0000 ( 6.1948)
Test: [2200/4166]  Time: 1.250 (1.205)  Loss:  6.9727 (6.0323)  Acc@1:  0.0000 ( 1.3441)  Acc@5:  0.0000 ( 6.1752)
Test: [2250/4166]  Time: 1.196 (1.205)  Loss:  6.3828 (6.0318)  Acc@1:  0.0000 ( 1.3550)  Acc@5:  0.0000 ( 6.1713)
Test: [2300/4166]  Time: 1.275 (1.206)  Loss:  6.3867 (6.0314)  Acc@1:  0.0000 ( 1.3581)  Acc@5:  8.3333 ( 6.1459)
Test: [2350/4166]  Time: 1.246 (1.207)  Loss:  5.9258 (6.0283)  Acc@1:  0.0000 ( 1.3505)  Acc@5:  8.3333 ( 6.1640)
Test: [2400/4166]  Time: 1.194 (1.207)  Loss:  7.0195 (6.0287)  Acc@1:  0.0000 ( 1.3571)  Acc@5:  0.0000 ( 6.1467)
Test: [2450/4166]  Time: 1.239 (1.207)  Loss:  7.0430 (6.0316)  Acc@1:  0.0000 ( 1.3396)  Acc@5:  8.3333 ( 6.1302)
Test: [2500/4166]  Time: 1.226 (1.208)  Loss:  6.3320 (6.0316)  Acc@1:  0.0000 ( 1.3395)  Acc@5:  0.0000 ( 6.1475)
Test: [2550/4166]  Time: 1.197 (1.208)  Loss:  6.0938 (6.0317)  Acc@1:  0.0000 ( 1.3230)  Acc@5:  0.0000 ( 6.1087)
Test: [2600/4166]  Time: 1.218 (1.208)  Loss:  6.2656 (6.0330)  Acc@1:  0.0000 ( 1.3296)  Acc@5:  8.3333 ( 6.1162)
Test: [2650/4166]  Time: 1.217 (1.208)  Loss:  6.1992 (6.0311)  Acc@1:  0.0000 ( 1.3234)  Acc@5: 16.6667 ( 6.1235)
Test: [2700/4166]  Time: 1.232 (1.209)  Loss:  6.3359 (6.0322)  Acc@1:  0.0000 ( 1.3267)  Acc@5:  0.0000 ( 6.1428)
Test: [2750/4166]  Time: 1.217 (1.209)  Loss:  6.9023 (6.0314)  Acc@1:  0.0000 ( 1.3298)  Acc@5:  0.0000 ( 6.1523)
Test: [2800/4166]  Time: 1.213 (1.209)  Loss:  5.5586 (6.0337)  Acc@1:  0.0000 ( 1.3150)  Acc@5:  8.3333 ( 6.1169)
Test: [2850/4166]  Time: 1.242 (1.209)  Loss:  6.2773 (6.0369)  Acc@1:  0.0000 ( 1.3007)  Acc@5: 16.6667 ( 6.0944)
Test: [2900/4166]  Time: 1.244 (1.210)  Loss:  6.3984 (6.0374)  Acc@1:  0.0000 ( 1.2898)  Acc@5:  0.0000 ( 6.0755)
Test: [2950/4166]  Time: 1.204 (1.211)  Loss:  6.2891 (6.0377)  Acc@1:  0.0000 ( 1.3103)  Acc@5:  0.0000 ( 6.0968)
Test: [3000/4166]  Time: 1.233 (1.211)  Loss:  5.4766 (6.0369)  Acc@1:  0.0000 ( 1.3107)  Acc@5: 16.6667 ( 6.0980)
Test: [3050/4166]  Time: 1.230 (1.211)  Loss:  5.1367 (6.0379)  Acc@1:  0.0000 ( 1.3110)  Acc@5: 16.6667 ( 6.0882)
Test: [3100/4166]  Time: 1.223 (1.211)  Loss:  5.4102 (6.0379)  Acc@1:  8.3333 ( 1.3087)  Acc@5: 25.0000 ( 6.0921)
Test: [3150/4166]  Time: 1.216 (1.211)  Loss:  6.5078 (6.0404)  Acc@1:  0.0000 ( 1.2985)  Acc@5:  0.0000 ( 6.0695)
Test: [3200/4166]  Time: 1.237 (1.212)  Loss:  5.5430 (6.0404)  Acc@1:  0.0000 ( 1.2991)  Acc@5:  0.0000 ( 6.0450)
Test: [3250/4166]  Time: 1.197 (1.212)  Loss:  5.3164 (6.0412)  Acc@1:  0.0000 ( 1.2996)  Acc@5:  8.3333 ( 6.0315)
Test: [3300/4166]  Time: 1.207 (1.212)  Loss:  4.8906 (6.0418)  Acc@1:  8.3333 ( 1.3052)  Acc@5: 25.0000 ( 6.0613)
Test: [3350/4166]  Time: 1.236 (1.212)  Loss:  6.2969 (6.0430)  Acc@1:  0.0000 ( 1.2981)  Acc@5: 16.6667 ( 6.0604)
Test: [3400/4166]  Time: 1.217 (1.212)  Loss:  6.7812 (6.0432)  Acc@1:  0.0000 ( 1.3011)  Acc@5:  0.0000 ( 6.0668)
Test: [3450/4166]  Time: 1.172 (1.212)  Loss:  6.1328 (6.0437)  Acc@1:  0.0000 ( 1.3016)  Acc@5:  8.3333 ( 6.0635)
Test: [3500/4166]  Time: 1.217 (1.212)  Loss:  5.6523 (6.0429)  Acc@1:  0.0000 ( 1.3044)  Acc@5:  8.3333 ( 6.0840)
Test: [3550/4166]  Time: 1.207 (1.213)  Loss:  5.9219 (6.0446)  Acc@1:  0.0000 ( 1.3048)  Acc@5:  0.0000 ( 6.0570)
Test: [3600/4166]  Time: 1.223 (1.213)  Loss:  6.0430 (6.0445)  Acc@1:  0.0000 ( 1.3098)  Acc@5:  0.0000 ( 6.0654)
Test: [3650/4166]  Time: 1.217 (1.213)  Loss:  6.1250 (6.0444)  Acc@1:  0.0000 ( 1.3101)  Acc@5:  0.0000 ( 6.0668)
Test: [3700/4166]  Time: 1.193 (1.213)  Loss:  5.5742 (6.0440)  Acc@1:  0.0000 ( 1.3105)  Acc@5:  0.0000 ( 6.0794)
Test: [3750/4166]  Time: 1.167 (1.212)  Loss:  4.8789 (6.0446)  Acc@1:  0.0000 ( 1.3019)  Acc@5: 25.0000 ( 6.0762)
Test: [3800/4166]  Time: 1.190 (1.212)  Loss:  7.1523 (6.0444)  Acc@1:  0.0000 ( 1.2957)  Acc@5:  0.0000 ( 6.0642)
Test: [3850/4166]  Time: 1.179 (1.211)  Loss:  5.7969 (6.0444)  Acc@1:  0.0000 ( 1.2919)  Acc@5:  0.0000 ( 6.0677)
Test: [3900/4166]  Time: 1.191 (1.211)  Loss:  7.2500 (6.0440)  Acc@1:  0.0000 ( 1.2967)  Acc@5:  0.0000 ( 6.0604)
Test: [3950/4166]  Time: 1.190 (1.211)  Loss:  6.1484 (6.0429)  Acc@1:  0.0000 ( 1.3035)  Acc@5:  8.3333 ( 6.0723)
Test: [4000/4166]  Time: 1.223 (1.210)  Loss:  5.6250 (6.0454)  Acc@1:  0.0000 ( 1.2934)  Acc@5:  0.0000 ( 6.0339)
Test: [4050/4166]  Time: 1.180 (1.210)  Loss:  6.1484 (6.0460)  Acc@1:  0.0000 ( 1.2877)  Acc@5:  8.3333 ( 6.0314)
Test: [4100/4166]  Time: 1.163 (1.210)  Loss:  6.1797 (6.0455)  Acc@1:  0.0000 ( 1.2802)  Acc@5:  8.3333 ( 6.0392)
Test: [4150/4166]  Time: 1.200 (1.209)  Loss:  5.5625 (6.0449)  Acc@1:  0.0000 ( 1.2808)  Acc@5:  8.3333 ( 6.0588)
Test: [4166/4166]  Time: 0.915 (1.209)  Loss:  5.8750 (6.0444)  Acc@1:  0.0000 ( 1.2820)  Acc@5: 12.5000 ( 6.0640)
Test (EMA): [   0/4166]  Time: 1.241 (1.241)  Loss:  5.6562 (5.6562)  Acc@1:  8.3333 ( 8.3333)  Acc@5:  8.3333 ( 8.3333)
Test (EMA): [  50/4166]  Time: 1.205 (1.208)  Loss:  7.2070 (6.0803)  Acc@1:  0.0000 ( 1.3072)  Acc@5:  0.0000 ( 6.0458)
Test (EMA): [ 100/4166]  Time: 1.208 (1.209)  Loss:  6.4844 (6.0829)  Acc@1:  0.0000 ( 1.5677)  Acc@5:  0.0000 ( 6.3531)
Test (EMA): [ 150/4166]  Time: 1.205 (1.206)  Loss:  6.0391 (6.0973)  Acc@1:  0.0000 ( 1.6556)  Acc@5:  0.0000 ( 6.2362)
Test (EMA): [ 200/4166]  Time: 1.202 (1.206)  Loss:  5.8594 (6.0778)  Acc@1:  0.0000 ( 1.5755)  Acc@5: 16.6667 ( 6.2604)
Test (EMA): [ 250/4166]  Time: 1.198 (1.204)  Loss:  6.2188 (6.0715)  Acc@1:  0.0000 ( 1.6268)  Acc@5:  8.3333 ( 6.5737)
Test (EMA): [ 300/4166]  Time: 1.199 (1.204)  Loss:  5.3438 (6.0820)  Acc@1:  8.3333 ( 1.6334)  Acc@5: 25.0000 ( 6.8106)
Test (EMA): [ 350/4166]  Time: 1.195 (1.203)  Loss:  6.1133 (6.1084)  Acc@1:  0.0000 ( 1.4720)  Acc@5:  0.0000 ( 6.5052)
Test (EMA): [ 400/4166]  Time: 1.193 (1.202)  Loss:  6.4180 (6.1089)  Acc@1:  0.0000 ( 1.4339)  Acc@5:  0.0000 ( 6.3591)
Test (EMA): [ 450/4166]  Time: 1.205 (1.202)  Loss:  6.3555 (6.1062)  Acc@1:  0.0000 ( 1.4228)  Acc@5:  0.0000 ( 6.2084)
Test (EMA): [ 500/4166]  Time: 1.206 (1.201)  Loss:  6.3477 (6.0993)  Acc@1:  0.0000 ( 1.4138)  Acc@5:  0.0000 ( 6.2542)
Test (EMA): [ 550/4166]  Time: 1.175 (1.201)  Loss:  6.3594 (6.1023)  Acc@1:  0.0000 ( 1.3460)  Acc@5:  0.0000 ( 6.1706)
Test (EMA): [ 600/4166]  Time: 1.197 (1.201)  Loss:  5.8594 (6.1051)  Acc@1:  0.0000 ( 1.3450)  Acc@5:  0.0000 ( 6.0871)
Test (EMA): [ 650/4166]  Time: 1.197 (1.200)  Loss:  6.4062 (6.1020)  Acc@1:  0.0000 ( 1.4081)  Acc@5:  8.3333 ( 6.0548)
Test (EMA): [ 700/4166]  Time: 1.197 (1.200)  Loss:  6.0117 (6.1056)  Acc@1:  0.0000 ( 1.3552)  Acc@5:  8.3333 ( 6.0747)
Test (EMA): [ 750/4166]  Time: 1.175 (1.200)  Loss:  5.8125 (6.1113)  Acc@1:  0.0000 ( 1.3316)  Acc@5:  0.0000 ( 6.0253)
Test (EMA): [ 800/4166]  Time: 1.194 (1.200)  Loss:  6.2344 (6.1117)  Acc@1:  8.3333 ( 1.3213)  Acc@5:  8.3333 ( 5.9821)
Test (EMA): [ 850/4166]  Time: 1.196 (1.199)  Loss:  5.7812 (6.1035)  Acc@1:  0.0000 ( 1.3611)  Acc@5:  0.0000 ( 6.0517)
Test (EMA): [ 900/4166]  Time: 1.191 (1.198)  Loss:  6.1602 (6.1052)  Acc@1:  0.0000 ( 1.3504)  Acc@5:  0.0000 ( 6.0766)
Test (EMA): [ 950/4166]  Time: 1.211 (1.198)  Loss:  6.3164 (6.1078)  Acc@1:  0.0000 ( 1.3670)  Acc@5:  0.0000 ( 6.0726)
Test (EMA): [1000/4166]  Time: 1.183 (1.198)  Loss:  6.2070 (6.1118)  Acc@1:  0.0000 ( 1.3487)  Acc@5:  8.3333 ( 6.0773)
Test (EMA): [1050/4166]  Time: 1.187 (1.197)  Loss:  6.5586 (6.1137)  Acc@1:  0.0000 ( 1.3400)  Acc@5:  0.0000 ( 6.0181)
Test (EMA): [1100/4166]  Time: 1.206 (1.197)  Loss:  6.1523 (6.1184)  Acc@1:  0.0000 ( 1.3170)  Acc@5:  0.0000 ( 5.9567)
Test (EMA): [1150/4166]  Time: 1.180 (1.197)  Loss:  5.8281 (6.1208)  Acc@1:  8.3333 ( 1.3611)  Acc@5:  8.3333 ( 5.9658)
Test (EMA): [1200/4166]  Time: 1.190 (1.197)  Loss:  5.6445 (6.1203)  Acc@1:  0.0000 ( 1.3392)  Acc@5:  8.3333 ( 5.9326)
Test (EMA): [1250/4166]  Time: 1.197 (1.197)  Loss:  7.0898 (6.1228)  Acc@1:  0.0000 ( 1.3189)  Acc@5:  0.0000 ( 5.9552)
Test (EMA): [1300/4166]  Time: 1.191 (1.197)  Loss:  7.3477 (6.1227)  Acc@1:  0.0000 ( 1.3067)  Acc@5:  0.0000 ( 5.9954)
Test (EMA): [1350/4166]  Time: 1.187 (1.197)  Loss:  6.4023 (6.1250)  Acc@1:  0.0000 ( 1.3200)  Acc@5: 16.6667 ( 6.0017)
Test (EMA): [1400/4166]  Time: 1.190 (1.196)  Loss:  5.8984 (6.1270)  Acc@1:  0.0000 ( 1.3145)  Acc@5: 16.6667 ( 5.9600)
Test (EMA): [1450/4166]  Time: 1.190 (1.196)  Loss:  7.1602 (6.1311)  Acc@1:  0.0000 ( 1.3094)  Acc@5:  0.0000 ( 5.9557)
Test (EMA): [1500/4166]  Time: 1.190 (1.196)  Loss:  5.3164 (6.1304)  Acc@1:  0.0000 ( 1.3158)  Acc@5:  8.3333 ( 5.9571)
Test (EMA): [1550/4166]  Time: 1.191 (1.196)  Loss:  6.7852 (6.1318)  Acc@1:  0.0000 ( 1.3217)  Acc@5:  0.0000 ( 5.9854)
Test (EMA): [1600/4166]  Time: 1.184 (1.196)  Loss:  5.9570 (6.1303)  Acc@1:  0.0000 ( 1.3273)  Acc@5:  0.0000 ( 6.0327)
Test (EMA): [1650/4166]  Time: 1.184 (1.195)  Loss:  6.7227 (6.1318)  Acc@1:  0.0000 ( 1.3224)  Acc@5:  0.0000 ( 6.0267)
Test (EMA): [1700/4166]  Time: 1.190 (1.195)  Loss:  5.6680 (6.1332)  Acc@1:  0.0000 ( 1.3130)  Acc@5:  8.3333 ( 6.0357)
Test (EMA): [1750/4166]  Time: 1.191 (1.195)  Loss:  5.6602 (6.1341)  Acc@1:  8.3333 ( 1.3231)  Acc@5: 16.6667 ( 6.0632)
Test (EMA): [1800/4166]  Time: 1.166 (1.194)  Loss:  6.2383 (6.1347)  Acc@1:  0.0000 ( 1.3095)  Acc@5:  0.0000 ( 6.0614)
Test (EMA): [1850/4166]  Time: 1.167 (1.193)  Loss:  6.0234 (6.1328)  Acc@1:  0.0000 ( 1.3236)  Acc@5: 16.6667 ( 6.0688)
Test (EMA): [1900/4166]  Time: 1.166 (1.193)  Loss:  5.7031 (6.1306)  Acc@1:  0.0000 ( 1.3239)  Acc@5: 16.6667 ( 6.0494)
Test (EMA): [1950/4166]  Time: 1.170 (1.192)  Loss:  6.1562 (6.1260)  Acc@1:  0.0000 ( 1.3241)  Acc@5:  0.0000 ( 6.0866)
Test (EMA): [2000/4166]  Time: 1.178 (1.192)  Loss:  5.6250 (6.1250)  Acc@1:  8.3333 ( 1.3243)  Acc@5:  8.3333 ( 6.0761)
Test (EMA): [2050/4166]  Time: 1.170 (1.191)  Loss:  5.4219 (6.1249)  Acc@1:  0.0000 ( 1.3408)  Acc@5:  8.3333 ( 6.1027)
Test (EMA): [2100/4166]  Time: 1.170 (1.191)  Loss:  6.3828 (6.1243)  Acc@1:  0.0000 ( 1.3327)  Acc@5:  0.0000 ( 6.1003)
Test (EMA): [2150/4166]  Time: 1.169 (1.190)  Loss:  6.0000 (6.1226)  Acc@1:  0.0000 ( 1.3327)  Acc@5:  0.0000 ( 6.1057)
Test (EMA): [2200/4166]  Time: 1.170 (1.190)  Loss:  7.0742 (6.1246)  Acc@1:  0.0000 ( 1.3252)  Acc@5:  0.0000 ( 6.0881)
Test (EMA): [2250/4166]  Time: 1.186 (1.189)  Loss:  6.5039 (6.1243)  Acc@1:  0.0000 ( 1.3327)  Acc@5:  0.0000 ( 6.0936)
Test (EMA): [2300/4166]  Time: 1.165 (1.189)  Loss:  6.5703 (6.1239)  Acc@1:  0.0000 ( 1.3291)  Acc@5:  8.3333 ( 6.0771)
Test (EMA): [2350/4166]  Time: 1.206 (1.189)  Loss:  6.0078 (6.1207)  Acc@1:  0.0000 ( 1.3221)  Acc@5:  8.3333 ( 6.0932)
Test (EMA): [2400/4166]  Time: 1.170 (1.189)  Loss:  7.1914 (6.1212)  Acc@1:  0.0000 ( 1.3258)  Acc@5:  0.0000 ( 6.0773)
Test (EMA): [2450/4166]  Time: 1.194 (1.189)  Loss:  7.1445 (6.1243)  Acc@1:  0.0000 ( 1.3192)  Acc@5:  8.3333 ( 6.0588)
Test (EMA): [2500/4166]  Time: 1.206 (1.189)  Loss:  6.4258 (6.1244)  Acc@1:  0.0000 ( 1.3195)  Acc@5:  0.0000 ( 6.0676)
Test (EMA): [2550/4166]  Time: 1.225 (1.190)  Loss:  6.1445 (6.1245)  Acc@1:  0.0000 ( 1.3034)  Acc@5:  0.0000 ( 6.0303)
Test (EMA): [2600/4166]  Time: 1.197 (1.190)  Loss:  6.3594 (6.1259)  Acc@1:  0.0000 ( 1.3168)  Acc@5:  8.3333 ( 6.0329)
Test (EMA): [2650/4166]  Time: 1.197 (1.191)  Loss:  6.2695 (6.1240)  Acc@1:  0.0000 ( 1.3140)  Acc@5: 16.6667 ( 6.0417)
Test (EMA): [2700/4166]  Time: 1.195 (1.191)  Loss:  6.4648 (6.1251)  Acc@1:  0.0000 ( 1.3112)  Acc@5:  0.0000 ( 6.0595)
Test (EMA): [2750/4166]  Time: 1.169 (1.191)  Loss:  6.9609 (6.1241)  Acc@1:  0.0000 ( 1.3177)  Acc@5:  0.0000 ( 6.0705)
Test (EMA): [2800/4166]  Time: 1.198 (1.192)  Loss:  5.6367 (6.1265)  Acc@1:  0.0000 ( 1.3031)  Acc@5: 16.6667 ( 6.0455)
Test (EMA): [2850/4166]  Time: 1.179 (1.192)  Loss:  6.3789 (6.1298)  Acc@1:  0.0000 ( 1.2890)  Acc@5: 16.6667 ( 6.0184)
Test (EMA): [2900/4166]  Time: 1.202 (1.192)  Loss:  6.4922 (6.1303)  Acc@1:  0.0000 ( 1.2783)  Acc@5:  0.0000 ( 5.9922)
Test (EMA): [2950/4166]  Time: 1.191 (1.192)  Loss:  6.3281 (6.1306)  Acc@1:  0.0000 ( 1.2962)  Acc@5:  0.0000 ( 6.0121)
Test (EMA): [3000/4166]  Time: 1.238 (1.193)  Loss:  5.5078 (6.1296)  Acc@1:  0.0000 ( 1.2968)  Acc@5: 16.6667 ( 6.0147)
Test (EMA): [3050/4166]  Time: 1.214 (1.193)  Loss:  5.2031 (6.1307)  Acc@1:  0.0000 ( 1.3001)  Acc@5: 16.6667 ( 6.0090)
Test (EMA): [3100/4166]  Time: 1.233 (1.194)  Loss:  5.4766 (6.1307)  Acc@1:  8.3333 ( 1.2980)  Acc@5: 25.0000 ( 6.0196)
Test (EMA): [3150/4166]  Time: 1.223 (1.194)  Loss:  6.6875 (6.1333)  Acc@1:  0.0000 ( 1.2932)  Acc@5:  0.0000 ( 6.0007)
Test (EMA): [3200/4166]  Time: 1.228 (1.195)  Loss:  5.5820 (6.1332)  Acc@1:  0.0000 ( 1.2939)  Acc@5:  0.0000 ( 5.9825)
Test (EMA): [3250/4166]  Time: 1.225 (1.195)  Loss:  5.4102 (6.1339)  Acc@1:  0.0000 ( 1.2945)  Acc@5:  8.3333 ( 5.9674)
Test (EMA): [3300/4166]  Time: 1.233 (1.196)  Loss:  4.9844 (6.1346)  Acc@1:  8.3333 ( 1.3026)  Acc@5: 25.0000 ( 5.9982)
Test (EMA): [3350/4166]  Time: 1.232 (1.196)  Loss:  6.4062 (6.1358)  Acc@1:  0.0000 ( 1.2981)  Acc@5: 16.6667 ( 6.0131)
Test (EMA): [3400/4166]  Time: 1.247 (1.197)  Loss:  6.8945 (6.1361)  Acc@1:  0.0000 ( 1.2986)  Acc@5:  0.0000 ( 6.0129)
Test (EMA): [3450/4166]  Time: 1.245 (1.197)  Loss:  6.2109 (6.1366)  Acc@1:  0.0000 ( 1.2967)  Acc@5:  8.3333 ( 6.0055)
Test (EMA): [3500/4166]  Time: 1.204 (1.198)  Loss:  5.7383 (6.1359)  Acc@1:  0.0000 ( 1.3020)  Acc@5:  8.3333 ( 6.0292)
Test (EMA): [3550/4166]  Time: 1.197 (1.198)  Loss:  6.0078 (6.1376)  Acc@1:  0.0000 ( 1.3001)  Acc@5:  8.3333 ( 6.0030)
Test (EMA): [3600/4166]  Time: 1.256 (1.199)  Loss:  6.1367 (6.1375)  Acc@1:  0.0000 ( 1.3029)  Acc@5:  0.0000 ( 6.0099)
Test (EMA): [3650/4166]  Time: 1.217 (1.199)  Loss:  6.2109 (6.1374)  Acc@1:  0.0000 ( 1.3010)  Acc@5:  0.0000 ( 6.0143)
Test (EMA): [3700/4166]  Time: 1.228 (1.200)  Loss:  5.6797 (6.1369)  Acc@1:  0.0000 ( 1.3015)  Acc@5:  0.0000 ( 6.0322)
Test (EMA): [3750/4166]  Time: 1.199 (1.200)  Loss:  4.9531 (6.1375)  Acc@1:  0.0000 ( 1.2930)  Acc@5: 25.0000 ( 6.0251)
Test (EMA): [3800/4166]  Time: 1.260 (1.200)  Loss:  7.2852 (6.1374)  Acc@1:  0.0000 ( 1.2847)  Acc@5:  0.0000 ( 6.0138)
Test (EMA): [3850/4166]  Time: 1.247 (1.201)  Loss:  5.8711 (6.1375)  Acc@1:  0.0000 ( 1.2811)  Acc@5:  0.0000 ( 6.0114)
Test (EMA): [3900/4166]  Time: 1.244 (1.201)  Loss:  7.3906 (6.1371)  Acc@1:  0.0000 ( 1.2860)  Acc@5:  0.0000 ( 6.0027)
Test (EMA): [3950/4166]  Time: 1.224 (1.202)  Loss:  6.2695 (6.1360)  Acc@1:  8.3333 ( 1.2950)  Acc@5:  8.3333 ( 6.0111)
Test (EMA): [4000/4166]  Time: 1.215 (1.202)  Loss:  5.7383 (6.1386)  Acc@1:  0.0000 ( 1.2851)  Acc@5:  0.0000 ( 5.9735)
Test (EMA): [4050/4166]  Time: 1.225 (1.202)  Loss:  6.2461 (6.1392)  Acc@1:  0.0000 ( 1.2795)  Acc@5:  8.3333 ( 5.9738)
Test (EMA): [4100/4166]  Time: 1.200 (1.202)  Loss:  6.2578 (6.1387)  Acc@1:  0.0000 ( 1.2720)  Acc@5:  8.3333 ( 5.9782)
Test (EMA): [4150/4166]  Time: 1.206 (1.202)  Loss:  5.6445 (6.1380)  Acc@1:  0.0000 ( 1.2748)  Acc@5:  0.0000 ( 5.9925)
Test (EMA): [4166/4166]  Time: 0.857 (1.202)  Loss:  6.0156 (6.1376)  Acc@1:  0.0000 ( 1.2760)  Acc@5: 12.5000 ( 5.9980)
Current checkpoints:
 ('output/vit_base_patch16_224_in21k/cifar_100/ssf/20231120-125001-vit_base_patch16_224_in21k-224/checkpoint-0.pth.tar', 1.2760000955200195)

Train: 1 [   0/4166 (  0%)]  Loss: 5.927 (5.93)  Time: 2.652s,    4.52/s  (2.652s,    4.52/s)  LR: 1.001e-04  Data: 0.067 (0.067)
Train: 1 [  50/4166 (  1%)]  Loss: 5.526 (5.26)  Time: 2.536s,    4.73/s  (2.483s,    4.83/s)  LR: 1.001e-04  Data: 0.003 (0.003)
Train: 1 [ 100/4166 (  2%)]  Loss: 4.725 (5.10)  Time: 2.461s,    4.88/s  (2.483s,    4.83/s)  LR: 1.001e-04  Data: 0.002 (0.003)